from langchain_openai import ChatOpenAI
from langchain.schema import Document  
from langchain.schema import SystemMessage, HumanMessage
from langchain_openai import OpenAIEmbeddings  
from langchain_community.vectorstores import Chroma  

import os 
from dotenv import load_dotenv
import re

load_dotenv()

# API í‚¤ëŠ” .envì—ì„œ ìë™ ë¡œë“œë˜ë¯€ë¡œ ì—¬ê¸°ì„  ìƒëµ, temperature=0(ê²°ê³¼ ì¬í˜„ì„± ë†’ê²Œ)ë¡œ ìƒì„±
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.05)  

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# ê¸°ì¡´ì— ìƒì„±ëœ Chroma ë²¡í„° DB ë¡œë“œ
vector_db = Chroma(
    persist_directory="./my_rag_db", 
    embedding_function=embeddings,
    collection_name="admin_docs"
)

# 1. ì§ˆë¬¸ ì „ì²˜ë¦¬ ë° í™•ì¥ í•¨ìˆ˜
def preprocess_query(query: str) -> str:
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ì í•©í•˜ê²Œ ì „ì²˜ë¦¬"""
    # ê¸°ë³¸ ì •ê·œí™”
    query = query.strip()
    
    # êµ¬ì–´ì²´ -> í‘œì¤€ì–´ ë³€í™˜
    replacements = {
        'ëª» ì°': 'ìŠ¤ìº” ì•ˆë¨',
        'ì–´ë–¡í•´': 'ì–´ë–»ê²Œ í•´ì•¼',
        'ë­ì•¼': 'ë¬´ì—‡ì¸ê°€ìš”',
        'ì–´ì¼€': 'ì–´ë–»ê²Œ',
        'ì•ˆë¼': 'ì•ˆë©ë‹ˆë‹¤'
    }
    
    for old, new in replacements.items():
        query = query.replace(old, new)
    
    return query

def expand_query(query: str) -> str:
    """ì§ˆë¬¸ ì˜ë„ì— ë”°ë¥¸ í‚¤ì›Œë“œ í™•ì¥"""
    enhanced_query = query
    
    # QR ê´€ë ¨ ì§ˆë¬¸ í™•ì¥
    if any(word in query.lower() for word in ['qr', 'íì•Œ', 'ìŠ¤ìº”', 'ì°', 'ì½”ë“œ']):
        enhanced_query += " QRì½”ë“œ ì¶œì„ì²´í¬ ì¶œê²°í™•ì¸ ìŠ¤ìº” ì¸ì‹ ì˜¤ë¥˜ ëŒ€ì•ˆë°©ë²•"
    
    # ì¶œì„ ì¸ì • ê´€ë ¨
    if any(word in query.lower() for word in ['ì¸ì •', 'ì¸ì •ë°›', 'ìŠ¹ì¸']):
        enhanced_query += " ì¶œì„ì¸ì • ì¶œê²°ì¸ì • ìŠ¹ì¸ ì¸ì •ê¸°ì¤€"
    
    # ì •ì • ì‹ ì²­ ê´€ë ¨  
    if any(word in query.lower() for word in ['ì •ì •', 'ìˆ˜ì •', 'ë³€ê²½', 'ë°”ê¾¸']):
        enhanced_query += " ì •ì •ì‹ ì²­ ì¶œì„ì •ì • ìˆ˜ì • ë³€ê²½ ì ˆì°¨"
    
    # ìŠ¤í¬ë¦°ìƒ· ê´€ë ¨
    if any(word in query.lower() for word in ['ìŠ¤í¬ë¦°ìƒ·', 'í™”ë©´', 'ìº¡ì²˜', 'ì¦ë¹™']):
        enhanced_query += " ìŠ¤í¬ë¦°ìƒ· í™”ë©´ìº¡ì²˜ ì¦ë¹™ìë£Œ ì œì¶œ ìš”ê±´"
    
    # ì§€ê°/ê²°ì„ ê´€ë ¨
    if any(word in query.lower() for word in ['ì§€ê°', 'ê²°ì„', 'ëŠ¦', 'ë¹ ì§']):
        enhanced_query += " ì§€ê° ê²°ì„ ëŠ¦ìŒ ì¡°í‡´ ì¶œì„ì²˜ë¦¬"
    
    # ë¬¸ì˜/ì‹ ì²­ ê´€ë ¨
    if any(word in query.lower() for word in ['ë¬¸ì˜', 'ì‹ ì²­', 'ì–´ë””', 'ì–´ë–»ê²Œ']):
        enhanced_query += " ë¬¸ì˜ ì‹ ì²­ ì ˆì°¨ ë°©ë²• ë‹´ë‹¹ì ì—°ë½ì²˜"
    
    return enhanced_query

# 2. í–¥ìƒëœ ê²€ìƒ‰ í•¨ìˆ˜
def retrieve_chunks(query: str, k: int = 5) -> list[Document]:
    """ë‹¤ë‹¨ê³„ ê²€ìƒ‰ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ"""
    
    # 1ë‹¨ê³„: ì „ì²˜ë¦¬ëœ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰
    processed_query = preprocess_query(query)
    enhanced_query = expand_query(processed_query)
    
    print(f"ğŸ” ì›ë³¸ ì§ˆë¬¸: {query}")
    print(f"ğŸ” í™•ì¥ëœ ì§ˆë¬¸: {enhanced_query}")
    
    # 2ë‹¨ê³„: ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰
    primary_results = vector_db.similarity_search(enhanced_query, k=k*2)
    
    # 3ë‹¨ê³„: MMR(Maximum Marginal Relevance) ê²€ìƒ‰ìœ¼ë¡œ ë‹¤ì–‘ì„± í™•ë³´
    try:
        mmr_results = vector_db.max_marginal_relevance_search(
            enhanced_query, 
            k=k, 
            fetch_k=k*2,
            lambda_mult=0.7  # ê´€ë ¨ì„±ê³¼ ë‹¤ì–‘ì„± ê· í˜•
        )
    except:
        mmr_results = primary_results[:k]
    
    # 4ë‹¨ê³„: ê²°ê³¼ í’ˆì§ˆ í‰ê°€ ë° í•„í„°ë§
    filtered_results = []
    query_keywords = set(re.findall(r'\w+', query.lower()))
    
    for doc in mmr_results:
        content_lower = doc.page_content.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        matching_keywords = sum(1 for keyword in query_keywords if keyword in content_lower)
        
        # ìµœì†Œ ê´€ë ¨ì„± ê¸°ì¤€ (í‚¤ì›Œë“œê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì œì™¸)
        if matching_keywords > 0 or len(filtered_results) < 2:  # ìµœì†Œ 2ê°œëŠ” ë³´ì¥
            filtered_results.append(doc)
    
    return filtered_results[:k]

# 3. í–¥ìƒëœ ë‹µë³€ ìƒì„± í•¨ìˆ˜
def generate_answer(query: str, chunks: list[Document]) -> str:
    """ë¬¸ë§¥ì„ ê³ ë ¤í•œ ì •í™•í•œ ë‹µë³€ ìƒì„±"""
    
    if not chunks:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì‹œê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ì§ì ‘ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
    
    # ë¬¸ì„œ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì œê³µ
    docs_text = ""
    for i, doc in enumerate(chunks):
        source_info = doc.metadata.get('source_file') or doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
        keywords = doc.metadata.get('keywords', '')
        
        docs_text += f"[ë¬¸ì„œ {i+1}] (ì¶œì²˜: {source_info})\n"
        if keywords:
            docs_text += f"ê´€ë ¨í‚¤ì›Œë“œ: {keywords}\n"
        docs_text += f"{doc.page_content}\n\n"
    
    # í–¥ìƒëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = (
        "ë‹¹ì‹ ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ ìˆ˜ê°•ìƒì„ ìœ„í•œ ì „ë¬¸ í–‰ì • ì±—ë´‡ì…ë‹ˆë‹¤.\n\n"
        "ë‹µë³€ ì›ì¹™:\n"
        "1. ì œê³µëœ ë¬¸ì„œì˜ ì •í™•í•œ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”\n"
        "2. ì‚¬ìš©ì ì§ˆë¬¸ì´ êµ¬ì–´ì²´ë‚˜ ë¶ˆì™„ì „í•œ ë¬¸ì¥ì´ì–´ë„ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”\n"
        "3. êµ¬ì²´ì ì¸ ì ˆì°¨ë‚˜ ë°©ë²•ì´ ìˆë‹¤ë©´ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ì„¸ìš”\n"
        "4. ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ ë‚´ìš©ì€ 'ë¬¸ì„œì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤'ë¼ê³  ëª…í™•íˆ ë‹µë³€í•˜ì„¸ìš”\n"
        "5. ì—°ë½ì²˜ë‚˜ ë‹´ë‹¹ì ì •ë³´ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”\n"
        "6. ë‹µë³€ì€ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•˜ì„¸ìš”"
    )
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=(
            f"ì‚¬ìš©ì ì§ˆë¬¸: \"{query}\"\n\n"
            f"ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:\n{docs_text}\n\n"
            "ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”:"
        ))
    ]
    
    try:
        response = llm.invoke(messages)
        answer = response.content.strip()
        
        # ë‹µë³€ í’ˆì§ˆ ê²€ì¦
        if len(answer) < 10:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì •ë¦¬í•´ì„œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
        
        return answer
    
    except Exception as e:
        print(f"âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

# 4. ê°œì„ ëœ ì „ì²´ íë¦„ í•¨ìˆ˜
def answer(query: str, top_k: int = 5) -> str:
    """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ ìƒì„±"""
    
    if not query or query.strip() == "":
        return "ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."
    
    try:
        # ê²€ìƒ‰ ë‹¨ê³„
        chunks = retrieve_chunks(query, k=top_k)
        
        print(f"ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(chunks)}")
        
        # ë‹µë³€ ìƒì„± ë‹¨ê³„
        answer_text = generate_answer(query, chunks)
        
        return answer_text
    
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."

# 5. ë””ë²„ê¹…ìš© ìƒì„¸ ê²€ìƒ‰ í•¨ìˆ˜
def debug_search(query: str, top_k: int = 5) -> dict:
    """ê²€ìƒ‰ ê³¼ì •ì„ ìƒì„¸íˆ ë³´ì—¬ì£¼ëŠ” ë””ë²„ê¹… í•¨ìˆ˜"""
    
    processed_query = preprocess_query(query)
    enhanced_query = expand_query(processed_query)
    
    results = vector_db.similarity_search_with_score(enhanced_query, k=top_k)
    
    debug_info = {
        "original_query": query,
        "processed_query": processed_query,
        "enhanced_query": enhanced_query,
        "results_count": len(results),
        "results": []
    }
    
    for doc, score in results:
        debug_info["results"].append({
            "content_preview": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
            "similarity_score": score,
            "metadata": doc.metadata
        })
    
    return debug_info

# 6. í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
if __name__ == "__main__":
    test_queries = [
        "QR ëª» ì°ìœ¼ë©´ ì–´ë–¡í•´?",
        "ì¶œì„ ì •ì • ì–´ë–»ê²Œ ì‹ ì²­í•´?", 
        "ìŠ¤í¬ë¦°ìƒ· ì°ì–´ì„œ ì œì¶œí•˜ë©´ ë˜ë‚˜ìš”?",
        "ì§€ê°í–ˆëŠ”ë° ì¶œì„ ì¸ì •ë°›ì„ ìˆ˜ ìˆì–´?"
    ]
    
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    for query in test_queries:
        print(f"\n" + "="*50)
        print(f"ì§ˆë¬¸: {query}")
        print("-"*50)
        result = answer(query)
        print(f"ë‹µë³€: {result}")